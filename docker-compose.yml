version: "3"
services:

  gateway:
    image: nginxproxy/nginx-proxy
    volumes:
      - ./gateway_nginx.conf:/etc/nginx/nginx.conf:ro
      - /var/run/docker.sock:/tmp/docker.sock:ro
    ports:
      - "8000:80"
    depends_on:
      - order-service
      - stock-service
      - payment-service
      - orchestrator-service

  orchestrator-service:
    build:
        context: .
        dockerfile: ./orchestrator/Dockerfile
    image: orchestrator:latest
    environment:
    - GATEWAY_URL=http://gateway:80
    - KAFKA_BOOTSTRAP_SERVERS=kafka:29092,kafka2:29093,kafka3:29094
    command: hypercorn app:app --bind 0.0.0.0:5000 --workers 1 --graceful-timeout 30 --log-level info
    depends_on:
      init_kafka:
        condition: service_completed_successfully
    restart: always
    scale: 3

  order-service:
    build:
      context: .
      dockerfile: ./order/Dockerfile
    image: order:latest
    environment:
    - GATEWAY_URL=http://gateway:80
    - KAFKA_BOOTSTRAP_SERVERS=kafka:29092,kafka2:29093,kafka3:29094
    - VIRTUAL_HOST=order.localhost
    command: hypercorn app:app --bind 0.0.0.0:5000 --workers 1 --graceful-timeout 30 --log-level info
    env_file:
      - env/order_redis.env
    depends_on:
      init_kafka:
        condition: service_completed_successfully
      order-db:
        condition: service_started
    restart: always
    scale: 3
    networks:
      - default
      - redis-net
  
  order-db:
    image: redis:7.2-bookworm
    container_name: order-db
    command: redis-server --masterauth redis --requirepass redis --maxmemory 512mb
    restart: always
    networks:
      redis-net:
        ipv4_address: 172.25.0.6

  order-db-replica:
    image: redis:7.2-bookworm
    container_name: order-db-replica
    restart: always
    command: redis-server --replicaof 172.25.0.6 6379 --masterauth redis --requirepass redis --maxmemory 512mb
    depends_on:
      - order-db
    networks:
      redis-net:
        ipv4_address: 172.25.0.7

  stock-service:
    build:
      context: .
      dockerfile: ./stock/Dockerfile
    image: stock:latest
    environment:
      - GATEWAY_URL=http://gateway:80
      - KAFKA_BOOTSTRAP_SERVERS=kafka:29092,kafka2:29093,kafka3:29094
      - VIRTUAL_HOST=stock.localhost
    command: hypercorn app:app --bind 0.0.0.0:5000 --workers 1 --graceful-timeout 30 --log-level info
    env_file:
      - env/stock_redis.env
    depends_on:
      init_kafka:
        condition: service_completed_successfully
      stock-db:
        condition: service_started
    scale: 3
    restart: always
    networks:
      - default
      - redis-net

  stock-db:
    image: redis:7.2-bookworm
    container_name: stock-db
    command: redis-server --masterauth redis --requirepass redis --maxmemory 512mb
    restart: always
    networks:
      redis-net:
        ipv4_address: 172.25.0.8

  stock-db-replica:
    image: redis:7.2-bookworm
    container_name: stock-db-replica
    restart: always
    command: redis-server --masterauth redis --requirepass redis --replicaof 172.25.0.8 6379 --maxmemory 512mb
    depends_on:
      - stock-db
    networks:
      redis-net:
        ipv4_address: 172.25.0.9

  payment-service:
    build:
      context: .
      dockerfile: ./payment/Dockerfile
    image: user:latest
    environment:
      - GATEWAY_URL=http://gateway:80
      - KAFKA_BOOTSTRAP_SERVERS=kafka:29092,kafka2:29093,kafka3:29094
      - VIRTUAL_HOST=payment.localhost
    command: hypercorn app:app --bind 0.0.0.0:5000 --workers 1 --graceful-timeout 30 --log-level info
    env_file:
      - env/payment_redis.env
    depends_on:
      init_kafka:
        condition: service_completed_successfully
      payment-db:
        condition: service_started
      payment-db-replica:
        condition: service_started
    scale: 3
    restart: always
    networks:
      - default
      - redis-net

  payment-db:
    image: redis:7.2-bookworm
    container_name: payment-db
    command: redis-server --requirepass redis --masterauth redis --maxmemory 512mb
    restart: always
    networks:
      redis-net:
        ipv4_address: 172.25.0.10

  payment-db-replica:
    image: redis:7.2-bookworm
    container_name: payment-db-replica
    command: redis-server --masterauth redis --requirepass redis --replicaof 172.25.0.10 6379 --maxmemory 512mb
    restart: always
    depends_on:
      - payment-db
    networks:
      redis-net:
        ipv4_address: 172.25.0.11

  sentinel-1:
    build: ./redis-sentinel
    container_name: sentinel-1
    volumes:
      - ./redis-sentinel/sentinel.conf.template:/etc/redis/sentinel.conf.template
      - ./env:/env:ro
    restart: always
    depends_on:
      - order-db
      - stock-db
      - payment-db
    networks:
      redis-net:
        ipv4_address: 172.25.0.3

  sentinel-2:
    build: ./redis-sentinel
    container_name: sentinel-2
    volumes:
      - ./redis-sentinel/sentinel.conf.template:/etc/redis/sentinel.conf.template
      - ./env:/env:ro
    restart: always
    depends_on:
      - order-db
      - stock-db
      - payment-db
    networks:
      redis-net:
        ipv4_address: 172.25.0.4

  kafka:
    image: confluentinc/cp-kafka:latest
    container_name: kafka
    ports:
      - 9092:9092
    environment :
      KAFKA_BROKER_ID: 1
      KAFKA_PROCESS_ROLES: broker,controller
      KAFKA_LISTENERS: BROKER://:29092,PLAINTEXT_HOST://:9092,CONTROLLER://:19092
      KAFKA_CONTROLLER_QUORUM_VOTERS: 1@kafka:19092,2@kafka2:19093,3@kafka3:19094
      KAFKA_ADVERTISED_LISTENERS: BROKER://kafka:29092,PLAINTEXT_HOST://localhost:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: BROKER:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT,CONTROLLER:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: BROKER
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 3
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "false"
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      CLUSTER_ID: D1QB5MB8QLml357eGLuJNg
      KAFKA_LOG4J_OPTS: >
        -Dlog4j.configuration=file:/opt/kafka/custom-log4j.properties
        -Dkafka.logs.dir=/var/log/kafka
        -Dkafka.logs.file.name=server-1.log
    healthcheck:
      test: nc -z localhost 9092 || exit -1
      start_period: 15s
      interval: 5s
      timeout: 10s
      retries: 10
    volumes:
      - ./kafka-logging/log4j.properties:/opt/kafka/custom-log4j.properties
      - kafka-logs:/var/log/kafka

  kafka2:
    image: confluentinc/cp-kafka:latest
    ports:
      - "9093:9093"
    environment:
      KAFKA_BROKER_ID: 2
      KAFKA_PROCESS_ROLES: broker,controller
      KAFKA_LISTENERS: BROKER://:29093,PLAINTEXT_HOST://:9093,CONTROLLER://:19093
      KAFKA_CONTROLLER_QUORUM_VOTERS: 1@kafka:19092,2@kafka2:19093,3@kafka3:19094
      KAFKA_ADVERTISED_LISTENERS: BROKER://kafka2:29093,PLAINTEXT_HOST://localhost:9093
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: BROKER:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT,CONTROLLER:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: BROKER
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 3
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "false"
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      CLUSTER_ID: D1QB5MB8QLml357eGLuJNg
      KAFKA_LOG4J_OPTS: >
        -Dlog4j.configuration=file:/opt/kafka/custom-log4j.properties
        -Dkafka.logs.dir=/var/log/kafka
        -Dkafka.logs.file.name=server-2.log
    healthcheck:
      test: nc -z localhost 9093 || exit -1
      start_period: 15s
      interval: 5s
      timeout: 10s
      retries: 10
    volumes:
      - ./kafka-logging/log4j.properties:/opt/kafka/custom-log4j.properties
      - kafka-logs:/var/log/kafka

  kafka3:
    image: confluentinc/cp-kafka:latest
    ports:
      - "9094:9094"
    environment:
      KAFKA_BROKER_ID: 3
      KAFKA_PROCESS_ROLES: broker,controller
      KAFKA_LISTENERS: BROKER://:29094,PLAINTEXT_HOST://:9094,CONTROLLER://:19094
      KAFKA_CONTROLLER_QUORUM_VOTERS: 1@kafka:19092,2@kafka2:19093,3@kafka3:19094
      KAFKA_ADVERTISED_LISTENERS: BROKER://kafka3:29094,PLAINTEXT_HOST://localhost:9094
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: BROKER:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT,CONTROLLER:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: BROKER
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 3
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "false"
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      CLUSTER_ID: D1QB5MB8QLml357eGLuJNg
      KAFKA_LOG4J_OPTS: >
        -Dlog4j.configuration=file:/opt/kafka/custom-log4j.properties
        -Dkafka.logs.dir=/var/log/kafka
        -Dkafka.logs.file.name=server-3.log
    healthcheck:
      test: nc -z localhost 9094 || exit -1
      start_period: 15s
      interval: 5s
      timeout: 10s
      retries: 10
    volumes:
      - ./kafka-logging/log4j.properties:/opt/kafka/custom-log4j.properties
      - kafka-logs:/var/log/kafka

  init_kafka:
    image: confluentinc/cp-kafka:latest
    depends_on:
      kafka:
        condition: service_healthy
      kafka2:
        condition: service_healthy
      kafka3:
        condition: service_healthy
    entrypoint: ["/bin/sh", "-c"]
    command: |
      "
      kafka-topics --bootstrap-server kafka:29092 --create --if-not-exists --topic checkout-operations --partitions 3 --replication-factor 3;
      kafka-topics --bootstrap-server kafka:29092 --create --if-not-exists --topic stock-operations --partitions 3 --replication-factor 3;
      kafka-topics --bootstrap-server kafka:29092 --create --if-not-exists --topic payment-operations --partitions 3 --replication-factor 3;
      kafka-topics --bootstrap-server kafka:29092 --create --if-not-exists --topic payment-responses --partitions 3 --replication-factor 3;
      kafka-topics --bootstrap-server kafka:29092 --create --if-not-exists --topic stock-responses --partitions 3 --replication-factor 3;
      kafka-topics --bootstrap-server kafka:29092 --create --if-not-exists --topic checkout-responses --partitions 3 --replication-factor 3;
      "


networks:
  redis-net:
    driver: bridge
    ipam:
      config:
        - subnet: 172.25.0.0/16


volumes:
  zookeeper_data:
  kafka-logs: