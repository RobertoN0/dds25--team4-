version: "3"
services:

  gateway:
    image: nginx:1.25-bookworm
    volumes:
      - ./gateway_nginx.conf:/etc/nginx/nginx.conf:ro
    ports:
      - "8000:80"
    depends_on:
      - order-service
      - stock-service
      - payment-service
      - orchestrator-service
    networks:
      - redis-net

  orchestrator-service:
    build:
        context: .
        dockerfile: ./orchestrator/Dockerfile
    image: orchestrator:latest
    environment:
    - GATEWAY_URL=http://gateway:80
    - OTEL_EXPORTER_OTLP_ENDPOINT=http://host.docker.internal:4317
    - OTEL_TRACES_EXPORTER=otlp
    - OTEL_METRICS_EXPORTER=otlp
    - OTEL_LOGS_EXPORTER=otlp
    - OTEL_SERVICE_NAME=orchestrator-service
    - OTEL_PYTHON_LOGGING_AUTO_INSTRUMENTATION_ENABLED=true
    - KAFKA_BOOTSTRAP_SERVERS=kafka:29092,kafka2:29093,kafka3:29094
    command: opentelemetry-instrument hypercorn app:app --bind 0.0.0.0:5000 --workers 1 --graceful-timeout 30 --log-level info
    depends_on:
      init_kafka:
        condition: service_completed_successfully
    restart: always
    scale: 3

  order-service:
    build:
      context: .
      dockerfile: ./order/Dockerfile
    image: order:latest
    environment:
    - GATEWAY_URL=http://gateway:80
    - OTEL_EXPORTER_OTLP_ENDPOINT=http://host.docker.internal:4317
    - OTEL_TRACES_EXPORTER=otlp
    - OTEL_METRICS_EXPORTER=otlp
    - OTEL_LOGS_EXPORTER=otlp
    - OTEL_SERVICE_NAME=order-service
    - OTEL_PYTHON_LOGGING_AUTO_INSTRUMENTATION_ENABLED=true
    - KAFKA_BOOTSTRAP_SERVERS=kafka:29092,kafka2:29093,kafka3:29094
    command: opentelemetry-instrument hypercorn app:app --bind 0.0.0.0:5000 --workers 1 --graceful-timeout 30 --log-level info
    env_file:
      - env/order_redis.env
    depends_on:
      init_kafka:
        condition: service_completed_successfully
      order-db:
        condition: service_started
    restart: always
    scale: 3
    networks:
      - default
      - redis-net
  
  order-db:
    image: redis:7.2-bookworm
    container_name: order-db
    command: redis-server --requirepass redis --masterauth redis --maxmemory 512mb
    restart: always
    networks:
      redis-net:
        ipv4_address: 172.25.0.6

  order-db-replica:
    image: redis:7.2-bookworm
    container_name: order-db-replica
    restart: always
    command: redis-server --replicaof 172.25.0.6 6379 --masterauth redis --requirepass redis --maxmemory 512mb
    depends_on:
      - order-db
    networks:
      redis-net:
        ipv4_address: 172.25.0.7

  stock-service:
    build:
      context: .
      dockerfile: ./stock/Dockerfile
    image: stock:latest
    environment:
      - GATEWAY_URL=http://gateway:80
      - OTEL_EXPORTER_OTLP_ENDPOINT=http://host.docker.internal:4317
      - OTEL_TRACES_EXPORTER=otlp
      - OTEL_METRICS_EXPORTER=otlp
      - OTEL_LOGS_EXPORTER=otlp
      - OTEL_SERVICE_NAME=stock-service
      - OTEL_PYTHON_LOGGING_AUTO_INSTRUMENTATION_ENABLED=true
      - KAFKA_BOOTSTRAP_SERVERS=kafka:29092,kafka2:29093,kafka3:29094
    command: opentelemetry-instrument hypercorn app:app --bind 0.0.0.0:5000 --workers 1 --graceful-timeout 30 --log-level info
    env_file:
      - env/stock_redis.env
    depends_on:
      init_kafka:
        condition: service_completed_successfully
      stock-db:
        condition: service_started
    scale: 3
    restart: always
    networks:
      - default
      - redis-net

  stock-db:
    image: redis:7.2-bookworm
    container_name: stock-db
    command: redis-server --requirepass redis --masterauth redis --maxmemory 512mb
    restart: always
    networks:
      redis-net:
        ipv4_address: 172.25.0.8

  stock-db-replica:
    image: redis:7.2-bookworm
    container_name: stock-db-replica
    restart: always
    command: redis-server --masterauth redis --requirepass redis --replicaof 172.25.0.8 6379 --maxmemory 512mb
    depends_on:
      - stock-db
    networks:
      redis-net:
        ipv4_address: 172.25.0.9

  payment-service:
    build:
      context: .
      dockerfile: ./payment/Dockerfile
    image: user:latest
    environment:
      - GATEWAY_URL=http://gateway:80
      - OTEL_EXPORTER_OTLP_ENDPOINT=http://host.docker.internal:4317
      - OTEL_TRACES_EXPORTER=otlp
      - OTEL_METRICS_EXPORTER=otlp
      - OTEL_LOGS_EXPORTER=otlp
      - OTEL_SERVICE_NAME=payment-service
      - OTEL_PYTHON_LOGGING_AUTO_INSTRUMENTATION_ENABLED=true
      - KAFKA_BOOTSTRAP_SERVERS=kafka:29092,kafka2:29093,kafka3:29094
    command: opentelemetry-instrument hypercorn app:app --bind 0.0.0.0:5000 --workers 1 --graceful-timeout 30 --log-level info
    env_file:
      - env/payment_redis.env
    depends_on:
      init_kafka:
        condition: service_completed_successfully
      payment-db-1:
        condition: service_started
      payment-db-2:
        condition: service_started
    scale: 3
    restart: always
    networks:
      - default
      - redis-net

  payment-db-1:
    image: redis:7.2-bookworm
    container_name: payment-db-1
    command: redis-server --requirepass redis --masterauth redis --maxmemory 512mb
    restart: always
    networks:
      redis-net:
        ipv4_address: 172.25.0.10

  payment-db-2:
    image: redis:7.2-bookworm
    container_name: payment-db-2
    command: redis-server --masterauth redis --requirepass redis --replicaof 172.25.0.10 6379 --maxmemory 512mb
    restart: always
    depends_on:
      - payment-db-1
    networks:
      redis-net:
        ipv4_address: 172.25.0.11

  sentinel-1:
    build: ./redis-sentinel
    container_name: sentinel-1
    volumes:
      - ./redis-sentinel/sentinel.conf.template:/etc/redis/sentinel.conf.template
      - ./env:/env:ro
    restart: always
    depends_on:
      - order-db
      - stock-db
      - payment-db-1
    networks:
      redis-net:
        ipv4_address: 172.25.0.3

  sentinel-2:
    build: ./redis-sentinel
    container_name: sentinel-2
    volumes:
      - ./redis-sentinel/sentinel.conf.template:/etc/redis/sentinel.conf.template
      - ./env:/env:ro
    restart: always
    depends_on:
      - order-db
      - stock-db
      - payment-db-1
    networks:
      redis-net:
        ipv4_address: 172.25.0.4

  aspire-dashboard:
    image: mcr.microsoft.com/dotnet/aspire-dashboard:8.1.0
    ports:
      - "18888:18888" # Dashboard UI
      - "4317:18889"  # OTLP receiver
    environment:
      - DOTNET_DASHBOARD_UNSECURED_ALLOW_ANONYMOUS=true

  zookeeper:
    image: confluentinc/cp-zookeeper:latest
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    ports:
      - "2181:2181"
    volumes:
    - zookeeper_data:/var/lib/zookeeper

  kafka:
    image: confluentinc/cp-kafka:latest
    container_name: kafka
    depends_on:
      - zookeeper
    ports:
      - 9092:9092
    environment :
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:29092,PLAINTEXT_HOST://0.0.0.0:9092
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:29092,PLAINTEXT_HOST://localhost:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 3
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "false"
      KAFKA_LOG4J_OPTS: >
        -Dlog4j.configuration=file:/opt/kafka/custom-log4j.properties
        -Dkafka.logs.dir=/var/log/kafka
        -Dkafka.logs.file.name=server-1.log
    healthcheck:
      test: nc -z localhost 9092 || exit -1
      start_period: 15s
      interval: 5s
      timeout: 10s
      retries: 10
    volumes:
      - ./kafka-logging/log4j.properties:/opt/kafka/custom-log4j.properties
      - kafka-logs:/var/log/kafka

  kafka2:
    image: confluentinc/cp-kafka:latest
    depends_on:
      - zookeeper
    ports:
      - "9093:9093"
    environment:
      KAFKA_BROKER_ID: 2
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:29093,PLAINTEXT_HOST://0.0.0.0:9093
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka2:29093,PLAINTEXT_HOST://localhost:9093
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 3
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "false"
      KAFKA_LOG4J_OPTS: >
        -Dlog4j.configuration=file:/opt/kafka/custom-log4j.properties
        -Dkafka.logs.dir=/var/log/kafka
        -Dkafka.logs.file.name=server-2.log
    healthcheck:
      test: nc -z localhost 9093 || exit -1
      start_period: 15s
      interval: 5s
      timeout: 10s
      retries: 10
    volumes:
      - ./kafka-logging/log4j.properties:/opt/kafka/custom-log4j.properties
      - kafka-logs:/var/log/kafka

  kafka3:
    image: confluentinc/cp-kafka:latest
    depends_on:
      - zookeeper
    ports:
      - "9094:9094"
    environment:
      KAFKA_BROKER_ID: 3
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:29094,PLAINTEXT_HOST://0.0.0.0:9094
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka3:29094,PLAINTEXT_HOST://localhost:9094
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 3
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "false"
      KAFKA_LOG4J_OPTS: >
        -Dlog4j.configuration=file:/opt/kafka/custom-log4j.properties
        -Dkafka.logs.dir=/var/log/kafka
        -Dkafka.logs.file.name=server-3.log
    healthcheck:
      test: nc -z localhost 9094 || exit -1
      start_period: 15s
      interval: 5s
      timeout: 10s
      retries: 10
    volumes:
      - ./kafka-logging/log4j.properties:/opt/kafka/custom-log4j.properties
      - kafka-logs:/var/log/kafka

  init_kafka:
    image: confluentinc/cp-kafka:latest
    depends_on:
      kafka:
        condition: service_healthy
      kafka2:
        condition: service_healthy
      kafka3:
        condition: service_healthy
    entrypoint: ["/bin/sh", "-c"]
    command: |
      "
      kafka-topics --bootstrap-server kafka:29092 --create --if-not-exists --topic checkout-operations --partitions 10 --replication-factor 3;
      kafka-topics --bootstrap-server kafka:29092 --create --if-not-exists --topic stock-operations --partitions 10 --replication-factor 3;
      kafka-topics --bootstrap-server kafka:29092 --create --if-not-exists --topic payment-operations --partitions 10 --replication-factor 3;
      kafka-topics --bootstrap-server kafka:29092 --create --if-not-exists --topic payment-responses --partitions 10 --replication-factor 3;
      kafka-topics --bootstrap-server kafka:29092 --create --if-not-exists --topic stock-responses --partitions 10 --replication-factor 3;
      kafka-topics --bootstrap-server kafka:29092 --create --if-not-exists --topic checkout-responses --partitions 10 --replication-factor 3;
      "


networks:
  redis-net:
    driver: bridge
    ipam:
      config:
        - subnet: 172.25.0.0/16


volumes:
  zookeeper_data:
  kafka-logs: